{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6268d5e",
   "metadata": {},
   "source": [
    "# OCR Label Generation for Invoice Dataset\n",
    "\n",
    "This notebook processes scanned invoice images and their corresponding key-value JSON files to generate:\n",
    "- Word-level OCR data using `pytesseract`\n",
    "- Bounding boxes for each word (normalized)\n",
    "- Token-level labels (`company`, `date`, `address`, `total`) using field text matching\n",
    "\n",
    "The final output is saved in HuggingFace Dataset format and can be directly used for training models like **LayoutLM** or **LayoutLMv2**.\n",
    "\n",
    "---\n",
    "\n",
    "### Steps Performed:\n",
    "1. Load invoice images and `.txt` annotation files (with fields in JSON)\n",
    "2. Extract OCR text and bounding boxes from images\n",
    "3. Match extracted tokens to annotation values to assign labels\n",
    "4. Save the output dataset using `datasets.Dataset` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8079c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amank\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from datasets import Dataset\n",
    "from pytesseract import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc447fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "data_root = Path(\"../data/sroie\")\n",
    "image_dir = data_root / \"images\"\n",
    "anno_dir = data_root / \"annotations\"\n",
    "\n",
    "entries = []\n",
    "label_fields = [\"company\", \"date\", \"address\", \"total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323ffbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 626/626 [00:00<00:00, 38910.97 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed dataset to data/processed_invoice_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each image and its corresponding key-value .txt\n",
    "for filename in os.listdir(image_dir):\n",
    "    if not filename.endswith(\".jpg\"):\n",
    "        continue\n",
    "\n",
    "    img_path = image_dir / filename\n",
    "    anno_path = anno_dir / filename.replace(\".jpg\", \".txt\")\n",
    "\n",
    "    if not anno_path.exists():\n",
    "        print(f\"Annotation missing for {filename}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(anno_path, \"r\") as f:\n",
    "            key_data = json.load(f)\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        ocr_data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
    "\n",
    "        words = []\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(ocr_data['text'])):\n",
    "            word = ocr_data['text'][i].strip()\n",
    "            if not word:\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = (ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i])\n",
    "            box = [x, y, x + w, y + h]\n",
    "\n",
    "            assigned_label = \"O\"\n",
    "            for field in label_fields:\n",
    "                field_val = key_data.get(field, \"\").lower()\n",
    "                if word.lower() in field_val:\n",
    "                    assigned_label = f\"B-{field.upper()}\"\n",
    "                    break\n",
    "\n",
    "            words.append(word)\n",
    "            boxes.append(box)\n",
    "            labels.append(assigned_label)\n",
    "\n",
    "        entries.append({\n",
    "            \"image_path\": str(img_path.resolve()).replace(\"\\\\\", \"/\"),\n",
    "            \"words\": words,\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {filename}: {e}\")\n",
    "\n",
    "# Save as HuggingFace dataset\n",
    "if entries:\n",
    "    dataset = Dataset.from_list(entries)\n",
    "    dataset.save_to_disk(\"data/processed_invoice_dataset\")\n",
    "    print(\"Saved processed dataset to data/processed_invoice_dataset\")\n",
    "else:\n",
    "    print(\"No entries created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc26963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amank\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 626/626 [00:00<00:00, 56910.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed dataset to ../data/processed_invoice_dataset (n=626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "#  0. Imports\n",
    "# ─────────────────────────────────────────────\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from datasets import Dataset\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "#  1. Paths\n",
    "# ─────────────────────────────────────────────\n",
    "data_root   = Path(\"../data/sroie\")           # adjust if needed\n",
    "image_dir   = data_root / \"images\"\n",
    "anno_dir    = data_root / \"annotations\"\n",
    "\n",
    "output_path = \"../data/processed_invoice_dataset\"\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "#  2. Label configuration\n",
    "# ─────────────────────────────────────────────\n",
    "label_fields = [\"company\", \"date\", \"total\"]   # address removed for now\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Lowercase & strip all whitespace for robust matching.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \"\", text).lower()\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "#  3. Main loop – build entries list\n",
    "# ─────────────────────────────────────────────\n",
    "entries = []\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    if not filename.lower().endswith(\".jpg\"):\n",
    "        continue\n",
    "\n",
    "    img_path  = image_dir / filename\n",
    "    anno_path = anno_dir / filename.replace(\".jpg\", \".txt\")\n",
    "\n",
    "    if not anno_path.exists():\n",
    "        print(f\"[WARN] Annotation missing for {filename}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(anno_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            anno_data = json.load(f)\n",
    "\n",
    "        image    = Image.open(img_path).convert(\"RGB\")\n",
    "        ocr_data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
    "\n",
    "        words, boxes, labels = [], [], []\n",
    "\n",
    "        for i in range(len(ocr_data[\"text\"])):\n",
    "            word = ocr_data[\"text\"][i].strip()\n",
    "            if not word:\n",
    "                continue\n",
    "\n",
    "            # bounding-box in pixel coords (normalize later in training)\n",
    "            x, y, w, h = (\n",
    "                ocr_data[\"left\"][i],\n",
    "                ocr_data[\"top\"][i],\n",
    "                ocr_data[\"width\"][i],\n",
    "                ocr_data[\"height\"][i],\n",
    "            )\n",
    "            box = [x, y, x + w, y + h]\n",
    "\n",
    "            # ---------- label assignment ----------\n",
    "            assigned_label = \"O\"\n",
    "            clean_word     = clean_text(word)\n",
    "\n",
    "            for field in label_fields:\n",
    "                gt_value = str(anno_data.get(field, \"\"))\n",
    "                # split GT into tokens to allow partial matches\n",
    "                for part in gt_value.split():\n",
    "                    if clean_word in clean_text(part):\n",
    "                        assigned_label = f\"B-{field.upper()}\"\n",
    "                        break\n",
    "                if assigned_label != \"O\":\n",
    "                    break\n",
    "            # --------------------------------------\n",
    "\n",
    "            words.append(word)\n",
    "            boxes.append(box)\n",
    "            labels.append(assigned_label)\n",
    "\n",
    "        entries.append({\n",
    "            \"image_path\": str(img_path.resolve()).replace(\"\\\\\", \"/\"),\n",
    "            \"words\":      words,\n",
    "            \"boxes\":      boxes,\n",
    "            \"labels\":     labels\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed for {filename}: {e}\")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "#  4. Save as Hugging Face dataset\n",
    "# ─────────────────────────────────────────────\n",
    "if entries:\n",
    "    dataset = Dataset.from_list(entries)\n",
    "    dataset.save_to_disk(output_path)\n",
    "    print(f\"Saved processed dataset to {output_path} (n={len(entries)})\")\n",
    "else:\n",
    "    print(\"No entries created – check paths or annotations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
